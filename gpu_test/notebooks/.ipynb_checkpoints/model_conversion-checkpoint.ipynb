{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f6964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e90951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# [60000, 28, 28], [10000, 28, 28], [60000, ], [10000, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b45f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "dim = [(28 * 28,), 512, 512, 10]\n",
    "#input, first layer, second layer,output\n",
    "\n",
    "def makeModel(dim):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=dim[0]))\n",
    "    model.add(keras.layers.Dense(dim[1], activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(dim[2], activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(dim[3], activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = makeModel(dim)\n",
    "print(model.output_shape) # should be 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63cb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling\n",
    "\n",
    "optimizerMethod = \"adam\"\n",
    "lossFunction = \"categorical_crossentropy\"\n",
    "metricsLst = [\"accuracy\"]\n",
    "model.compile(optimizer=optimizerMethod, loss=lossFunction, metrics=metricsLst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and organize the data\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_train = x_train.reshape(60000, 28 * 28)/255.0\n",
    "x_test = x_test.reshape(10000, 28 * 28)/255.0\n",
    "\n",
    "nClass = 10\n",
    "y_train = keras.utils.to_categorical(y_train, nClass)\n",
    "y_test = keras.utils.to_categorical(y_test, nClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730139d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20, verbose=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "\n",
    "results = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Loss: \", results[0])\n",
    "print(\"Accuracy: \", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# model = tf.keras.applications.mobilenet.MobileNet(input_shape=(1, 28 * 28, 3), weights=None)\n",
    "# model.save('handwritten_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to use TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pathlib\n",
    "\n",
    "# tflite_models_dir = pathlib.Path(\"/tmp/mnist_tflite_models/\")\n",
    "# tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# # Save the unquantized/float model:\n",
    "# tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
    "# tflite_model_file.write_bytes(tflite_model)\n",
    "# # Save the quantized model:\n",
    "# tflite_model_quant_file = tflite_models_dir/\"mnist_model_quant.tflite\"\n",
    "# tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# tflite_models_dir = pathlib.Path(\"/tmp/mnist_tflite_models/\")\n",
    "# tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "# tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
    "# tflite_model_file.write_bytes(tflite_model)\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = pathlib.Path.cwd()/\"mnist_model_quant.tflite\"\n",
    "# with open('tflite_model_quant_file', 'wb') as f:\n",
    "#   f.write(tflite_model_quant)\n",
    "# tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global x_test\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = x_test[test_image_index]\n",
    "    test_label = y_test[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    \n",
    "    # reshape test_image\n",
    "    test_image = tf.reshape(test_image, [1, 784])\n",
    "    \n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Change this to test a different image\n",
    "test_image_index = 1\n",
    "\n",
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_file, test_image_index, model_type):\n",
    "  global y_test\n",
    "\n",
    "  predictions = run_tflite_model(tflite_file, [test_image_index])\n",
    "\n",
    "  tmp = tf.reshape(x_test[test_image_index], [28, 28])\n",
    "  plt.imshow(tmp)\n",
    "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
    "  _ = plt.title(template.format(true= str(y_test[test_image_index]), predict=str(predictions[0])))\n",
    "  plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClass(lst):\n",
    "    return np.argmax(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "  global x_test\n",
    "  global y_test\n",
    "\n",
    "  test_image_indices = range(x_test.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "  tmp = [getClass(e) for e in y_test]\n",
    "\n",
    "  accuracy = (np.sum(tmp == predictions) * 100) / len(x_test)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy is 8.4900% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"mnist_model_quant.tflite\", model_type=\"Quantized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
